<!DOCTYPE html>


<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RFC 9309 - Robots Exclusion Protocol 日本語訳</title>
  <meta name="description" content="RFC 9309は、サービス所有者がクローラーによるコンテンツのアクセスを制御するための「Robots Exclusion Protocol」を定義し拡張する。プロトコルの定義言語、エラー処理、およびキャッシュの取り扱いに関する指示を追加することを目的としています。">

  
  <link rel="shortcut icon" type="image/x-icon" href="https://tex2e.github.io/rfc-translater/favicon.ico" />
  <link rel="stylesheet" href="./bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="./master.css">
  <script src="./index.js"></script>

</head>
<body>
  
  <nav class="navbar navbar-expand navbar-light bg-light">
    <a class="navbar-brand" href="index.html">RFC Trans</a>
    <div class="collapse navbar-collapse" id="navbarText">
      <div class="navbar-nav mr-auto">
        <a class="nav-item nav-link" href="draft/index.html">Draft</a>
        <a class="nav-item nav-link" href="contact.html">Contact</a>
        <a class="nav-item nav-link" href="../figs/html/index.html">Figs</a>
      </div>
      <div class="navbar-nav ml-auto">
        <span class="navbar-text"><small>@tex2e</small></span>
      </div>
    </div>
  </nav>

  <span id="rfc_number" class="hidden">9309</span>
  <div style="height: 1ex;"></div>
  <div class="jump-to-original-rfc-container">
    <a href="https://datatracker.ietf.org/doc/html/rfc9309">
      <button type="button" class="btn btn-light btn-sm">
        <span class="jump-to-original-rfc">Orig</span>
      </button>
    </a>
  </div>
  <div class="container">
    <div>
      <div class="alert alert-info" role="alert">
        <h4 class="alert-heading">RFC 9309 - Robots Exclusion Protocol 日本語訳</h4>
        <span class="URL">原文URL :
          <a href="https://datatracker.ietf.org/doc/html/rfc9309">
            https://datatracker.ietf.org/doc/html/rfc9309
          </a>
        </span><br>
        <span class="title_ja">
          タイトル : <strong>RFC 9309 - ロボット除外プロトコル</strong></span><br>
        <span class="updated_by">翻訳編集 : 自動生成</span><span id="rfc_status"></span><span id="rfc_wg"></span><br>
      </div>
      <div id="rfc_alert" class="hidden" role="alert">
        <div class="alert alert-danger">
          <span id="rfc_alert_obsoleted_by"></span>
        </div>
      </div>
    </div>
    <div id="rfc_summary">
      <div class="card mb-3">
        <div class="card-body">
          <p class="card-text">[要約] RFC 9309は、サービス所有者がクローラーによるコンテンツのアクセスを制御するための「Robots Exclusion Protocol」を定義し拡張する。プロトコルの定義言語、エラー処理、およびキャッシュの取り扱いに関する指示を追加することを目的としています。</p>
        </div>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
Internet Engineering Task Force (IETF)                         M. Koster
Request for Comments: 9309
Category: Standards Track                                      G. Illyes
ISSN: 2070-1721                                                H. Zeller
                                                              L. Sassman
                                                              Google LLC
                                                          September 2022
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-23">
Robots Exclusion Protocol
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-23">
ロボット除外プロトコル
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
Abstract
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
概要
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This document specifies and extends the &#34;Robots Exclusion Protocol&#34; method originally defined by Martijn Koster in 1994 for service owners to control how content served by their services may be accessed, if at all, by automatic clients known as crawlers. Specifically, it adds definition language for the protocol, instructions for handling errors, and instructions for caching.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントは、1994年にMartijn Kosterが元々Martijn Kosterによって定義されていた「ロボット除外プロトコル」メソッドを指定して拡張し、サービスが提供するコンテンツにクローラーと呼ばれる自動クライアントがサービスを提供するコンテンツにアクセスする方法を制御します。具体的には、プロトコルの定義言語、エラーの取り扱いの指示、およびキャッシュの指示を追加します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
Status of This Memo
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
本文書の位置付け
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This is an Internet Standards Track document.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
これは、インターネット標準トラックドキュメントです。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This document is a product of the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by the Internet Engineering Steering Group (IESG). Further information on Internet Standards is available in Section 2 of RFC 7841.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントは、インターネットエンジニアリングタスクフォース（IETF）の製品です。IETFコミュニティのコンセンサスを表しています。公開レビューを受けており、インターネットエンジニアリングステアリンググループ（IESG）からの出版が承認されています。インターネット標準の詳細については、RFC 7841のセクション2で入手できます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at https://www.rfc-editor.org/info/rfc9309.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントの現在のステータス、任意のERRATA、およびそのフィードバックを提供する方法に関する情報は、https：//www.rfc-editor.org/info/rfc9309で取得できます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
Copyright Notice
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
著作権表示
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Copyright (c) 2022 IETF Trust and the persons identified as the document authors. All rights reserved.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
著作権（c）2022 IETF Trustおよび文書著者として特定された人。全著作権所有。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This document is subject to BCP 78 and the IETF Trust&#39;s Legal Provisions Relating to IETF Documents (https://trustee.ietf.org/license-info) in effect on the date of publication of this document. Please review these documents carefully, as they describe your rights and restrictions with respect to this document. Code Components extracted from this document must include Revised BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Revised BSD License.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントは、BCP 78およびIETFドキュメント（https://trustee.ietf.org/license-info）に関連するIETF Trustの法的規定の対象となります。この文書に関するあなたの権利と制限を説明するので、これらの文書を注意深く確認してください。このドキュメントから抽出されたコードコンポーネントには、セクション4.Eで説明されている法的規定のセクション4.Eで説明されており、修正されたBSDライセンスで説明されているように保証なしで提供される修正されたBSDライセンステキストを含める必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
Table of Contents
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
目次
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace toc">
   1.  Introduction
     1.1.  Requirements Language
   2.  Specification
     2.1.  Protocol Definition
     2.2.  Formal Syntax
       2.2.1.  The User-Agent Line
       2.2.2.  The &#34;Allow&#34; and &#34;Disallow&#34; Lines
       2.2.3.  Special Characters
       2.2.4.  Other Records
     2.3.  Access Method
       2.3.1.  Access Results
         2.3.1.1.  Successful Access
         2.3.1.2.  Redirects
         2.3.1.3.  &#34;Unavailable&#34; Status
         2.3.1.4.  &#34;Unreachable&#34; Status
         2.3.1.5.  Parsing Errors
     2.4.  Caching
     2.5.  Limits
   3.  Security Considerations
   4.  IANA Considerations
   5.  Examples
     5.1.  Simple Example
     5.2.  Longest Match
   6.  References
     6.1.  Normative References
     6.2.  Informative References
   Authors&#39; Addresses
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="1--Introduction">
1. Introduction
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
1. はじめに
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This document applies to services that provide resources that clients can access through URIs as defined in [RFC3986]. For example, in the context of HTTP, a browser is a client that displays the content of a web page.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントは、[RFC3986]で定義されているように、クライアントがURIを介してアクセスできるリソースを提供するサービスに適用されます。たとえば、HTTPのコンテキストでは、ブラウザはWebページのコンテンツを表示するクライアントです。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers are automated clients. Search engines, for instance, have crawlers to recursively traverse links for indexing as defined in [RFC8288].
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは自動化されたクライアントです。たとえば、検索エンジンには、[RFC8288]で定義されているように、インデックスのためにリンクを再帰的に横断するクローラーがあります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
It may be inconvenient for service owners if crawlers visit the entirety of their URI space. This document specifies the rules originally defined by the &#34;Robots Exclusion Protocol&#34; [ROBOTSTXT] that crawlers are requested to honor when accessing URIs.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーがURIスペース全体を訪問した場合、サービスオーナーにとっては不便かもしれません。このドキュメントは、クローラーがURISにアクセスする際に名誉を求めるように要求される「ロボット除外プロトコル」[RobotStxt] [RobotStxt]で元々定義されたルールを指定します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
These rules are not a form of access authorization.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
これらのルールは、アクセス許可の一形態ではありません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="1-1--Requirements-Language">
1.1. Requirements Language
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
1.1. 要件言語
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The key words &#34;MUST&#34;, &#34;MUST NOT&#34;, &#34;REQUIRED&#34;, &#34;SHALL&#34;, &#34;SHALL NOT&#34;, &#34;SHOULD&#34;, &#34;SHOULD NOT&#34;, &#34;RECOMMENDED&#34;, &#34;NOT RECOMMENDED&#34;, &#34;MAY&#34;, and &#34;OPTIONAL&#34; in this document are to be interpreted as described in BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all capitals, as shown here.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
この文書のキーワード &#34;MUST&#34;, &#34;MUST NOT&#34;, &#34;REQUIRED&#34;, &#34;SHALL&#34;, &#34;SHALL NOT&#34;, &#34;SHOULD&#34;, &#34;SHOULD NOT&#34;, &#34;RECOMMENDED&#34;, &#34;MAY&#34;, および &#34;OPTIONAL&#34; はBCP 14 [RFC2119] [RFC8174]で説明されているように、すべて大文字の場合にのみ解釈されます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2--Specification">
2. Specification
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2. 仕様
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-1--Protocol-Definition">
2.1. Protocol Definition
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.1. プロトコル定義
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The protocol language consists of rule(s) and group(s) that the service makes available in a file named &#34;robots.txt&#34; as described in Section 2.3:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
プロトコル言語は、セクション2.3で説明されているように、「robots.txt」という名前のファイルでサービスが利用できるルールとグループで構成されています。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Rule: A line with a key-value pair that defines how a crawler may access URIs. See Section 2.2.2.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
ルール：クローラーがURISにアクセスする方法を定義するキー価値ペアのライン。セクション2.2.2を参照してください。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Group: One or more user-agent lines that are followed by one or more rules. The group is terminated by a user-agent line or end of file. See Section 2.2.1. The last group may have no rules, which means it implicitly allows everything.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
グループ：1つ以上のルールが続く1つ以上のユーザーエージェント行。グループは、ユーザーエージェント行またはファイルの終了によって終了します。セクション2.2.1を参照してください。最後のグループにはルールがない場合があります。つまり、暗黙的にすべてを許可します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-2--Formal-Syntax">
2.2. Formal Syntax
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.2. 正式な構文
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Below is an Augmented Backus-Naur Form (ABNF) description, as described in [RFC5234].
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
以下は、[RFC5234]で説明されているように、拡張されたバックスノール形式（ABNF）の説明です。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    robotstxt = *(group / emptyline)
    group = startgroupline                ; We start with a user-agent
                                          ; line
           *(startgroupline / emptyline)  ; ... and possibly more
                                          ; user-agent lines
           *(rule / emptyline)            ; followed by rules relevant
                                          ; for the preceding
                                          ; user-agent lines
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    startgroupline = *WS &#34;user-agent&#34; *WS &#34;:&#34; *WS product-token EOL
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    rule = *WS (&#34;allow&#34; / &#34;disallow&#34;) *WS &#34;:&#34;
          *WS (path-pattern / empty-pattern) EOL
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-4">
; parser implementors: define additional lines you need (for ; example, Sitemaps).
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-4">
;パーサーの実装者：必要な追加の行を定義します（例、SiteMapsなど）。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    product-token = identifier / &#34;*&#34;
    path-pattern = &#34;/&#34; *UTF8-char-noctl ; valid URI path pattern
    empty-pattern = *WS
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    identifier = 1*(%x2D / %x41-5A / %x5F / %x61-7A)
    comment = &#34;#&#34; *(UTF8-char-noctl / WS / &#34;#&#34;)
    emptyline = EOL
    EOL = *WS [comment] NL ; end-of-line may have
                           ; optional trailing comment
    NL = %x0D / %x0A / %x0D.0A
    WS = %x20 / %x09
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-4">
; UTF8 derived from RFC 3629, but excluding control characters
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-4">
;RFC 3629から派生したUTF8ですが、コントロール文字を除く
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    UTF8-char-noctl = UTF8-1-noctl / UTF8-2 / UTF8-3 / UTF8-4
    UTF8-1-noctl = %x21 / %x22 / %x24-7F ; excluding control, space, &#34;#&#34;
    UTF8-2 = %xC2-DF UTF8-tail
    UTF8-3 = %xE0 %xA0-BF UTF8-tail / %xE1-EC 2UTF8-tail /
             %xED %x80-9F UTF8-tail / %xEE-EF 2UTF8-tail
    UTF8-4 = %xF0 %x90-BF 2UTF8-tail / %xF1-F3 3UTF8-tail /
             %xF4 %x80-8F 2UTF8-tail
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    UTF8-tail = %x80-BF
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-2-1--The-User-Agent-Line">
2.2.1. The User-Agent Line
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.2.1. ユーザーエージェントライン
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers set their own name, which is called a product token, to find relevant groups. The product token MUST contain only uppercase and lowercase letters (&#34;a-z&#34; and &#34;A-Z&#34;), underscores (&#34;_&#34;), and hyphens (&#34;-&#34;). The product token SHOULD be a substring of the identification string that the crawler sends to the service. For example, in the case of HTTP [RFC9110], the product token SHOULD be a substring in the User-Agent header. The identification string SHOULD describe the purpose of the crawler. Here&#39;s an example of a User-Agent HTTP request header with a link pointing to a page describing the purpose of the ExampleBot crawler, which appears as a substring in the User-Agent HTTP header and as a product token in the robots.txt user-agent line:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlersは、関連するグループを見つけるために、製品トークンと呼ばれる独自の名前を設定します。製品トークンには、大文字と小文字（ &#34;a-z&#34; and &#34;a-z&#34;）のみ、アンダースコア（ &#34;_&#34;）、およびハイフン（ &#34; - &#34;）のみを含める必要があります。製品トークンは、クローラーがサービスに送る識別文字列のサブストリングである必要があります。たとえば、HTTP [RFC9110]の場合、製品トークンはユーザーエージェントヘッダーのサブストリングである必要があります。識別文字列は、クローラーの目的を説明する必要があります。ユーザーエージェントHTTPリクエストヘッダーの例は、ユーザーエージェントHTTPヘッダーのサブストリングとして、およびrobots.txtユーザーの製品トークンとして表示される、ExampleBot Crawlerの目的を説明するページを指すリンクを備えた例です。エージェントライン：
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
   +==========================================+========================+
   | User-Agent HTTP header                   | robots.txt user-agent  |
   |                                          | line                   |
   +==========================================+========================+
   | User-Agent: Mozilla/5.0 (compatible;     | user-agent: ExampleBot |
   | ExampleBot/0.1;                          |                        |
   | https://www.example.com/bot.html)        |                        |
   +------------------------------------------+------------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-8">
Figure 1: Example of a User-Agent HTTP header and robots.txt user-agent line for the ExampleBot product token
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-8">
図1：ユーザーエージェントのhttpヘッダーとrobots.txtの例ボット製品トークンのユーザーエージェントライン
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Note that the product token (ExampleBot) is a substring of the User-Agent HTTP header.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
製品トークン（ExampleBot）は、ユーザーエージェントHTTPヘッダーのサブストリングであることに注意してください。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers MUST use case-insensitive matching to find the group that matches the product token and then obey the rules of the group. If there is more than one group matching the user-agent, the matching groups&#39; rules MUST be combined into one group and parsed according to Section 2.2.2.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlersは、Case-Ensensive Matteringを使用して、製品トークンに一致するグループを見つけてから、グループのルールに従う必要があります。ユーザーエージェントに一致する複数のグループがある場合、マッチンググループのルールを1つのグループに組み合わせて、セクション2.2.2に従って解析する必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    +========================================+========================+
    | Two groups that match the same product | Merged group           |
    | token exactly                          |                        |
    +========================================+========================+
    | user-agent: ExampleBot                 | user-agent: ExampleBot |
    | disallow: /foo                         | disallow: /foo         |
    | disallow: /bar                         | disallow: /bar         |
    |                                        | disallow: /baz         |
    | user-agent: ExampleBot                 |                        |
    | disallow: /baz                         |                        |
    +----------------------------------------+------------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-8">
Figure 2: Example of how to merge two robots.txt groups that match the same product token
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-8">
図2：同じ製品トークンに一致する2つのrobots.txtグループをマージする方法の例
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If no matching group exists, crawlers MUST obey the group with a user-agent line with the &#34;*&#34; value, if present.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
一致するグループが存在しない場合、クローラーは、存在する場合、「*」値を持つユーザーエージェントラインでグループに従わなければなりません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
        +==================================+======================+
        | Two groups that don&#39;t explicitly | Applicable group for |
        | match ExampleBot                 | ExampleBot           |
        +==================================+======================+
        | user-agent: *                    | user-agent: *        |
        | disallow: /foo                   | disallow: /foo       |
        | disallow: /bar                   | disallow: /bar       |
        |                                  |                      |
        | user-agent: BazBot               |                      |
        | disallow: /baz                   |                      |
        +----------------------------------+----------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-7">
Figure 3: Example of no matching groups other than the &#34;*&#34; for the ExampleBot product token
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-7">
図3：例ボット製品トークンの「*」以外の一致するグループがない例
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If no group matches the product token and there is no group with a user-agent line with the &#34;*&#34; value, or no groups are present at all, no rules apply.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
製品トークンと一致するグループがなく、「*」値を持つユーザーエージェントラインを持つグループがない場合、またはグループがまったく存在しない場合、ルールは適用されません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-2-2--The-Allow-and-Disallow-Lines">
2.2.2. The &#34;Allow&#34; and &#34;Disallow&#34; Lines
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.2.2. 「許可」と「許可」行
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
These lines indicate whether accessing a URI that matches the corresponding path is allowed or disallowed.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
これらの行は、対応するパスに一致するURIにアクセスするかどうかを示しています。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
To evaluate if access to a URI is allowed, a crawler MUST match the paths in &#34;allow&#34; and &#34;disallow&#34; rules against the URI. The matching SHOULD be case sensitive. The matching MUST start with the first octet of the path. The most specific match found MUST be used. The most specific match is the match that has the most octets. Duplicate rules in a group MAY be deduplicated. If an &#34;allow&#34; rule and a &#34;disallow&#34; rule are equivalent, then the &#34;allow&#34; rule SHOULD be used. If no match is found amongst the rules in a group for a matching user-agent or there are no rules in the group, the URI is allowed. The /robots.txt URI is implicitly allowed.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
URIへのアクセスが許可されているかどうかを評価するには、クローラーはURIに対する「許可」および「許可」のパスと一致する必要があります。マッチングはケースに敏感でなければなりません。マッチングは、パスの最初のオクテットから開始する必要があります。見つかった最も具体的な一致を使用する必要があります。最も具体的な試合は、オクテットが最も多い試合です。グループ内の複製ルールは重複している場合があります。「許可」ルールと「許可」ルールが同等である場合、「許可」ルールを使用する必要があります。一致するユーザーエージェントのグループのルールの間で一致しない場合、またはグループにルールがない場合、URIは許可されます。/robots.txt uriは暗黙的に許可されています。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Octets in the URI and robots.txt paths outside the range of the ASCII coded character set, and those in the reserved range defined by [RFC3986], MUST be percent-encoded as defined by [RFC3986] prior to comparison.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
URIおよびrobots.txtのオクテットは、ASCIIコード化された文字セットの範囲外のパス、および[RFC3986]で定義された予約範囲のパスは、比較前に[RFC3986]によって定義されているようにパーセントエンコードする必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If a percent-encoded ASCII octet is encountered in the URI, it MUST be unencoded prior to comparison, unless it is a reserved character in the URI as defined by [RFC3986] or the character is outside the unreserved character range. The match evaluates positively if and only if the end of the path from the rule is reached before a difference in octets is encountered.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
URIでエンコードされたASCIIオクテットが遭遇した場合、[RFC3986]で定義されているURIの予約されたキャラクターである場合、またはキャラクターが非予定のキャラクター範囲外でない限り、比較前にエンコードされない必要があります。オクテットの差に遭遇する前に、ルールからのパスの終了に到達した場合にのみ、試合は積極的に評価されます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
For example:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
例えば：
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
   +==================+=======================+=======================+
   | Path             | Encoded Path          | Path to Match         |
   +==================+=======================+=======================+
   | /foo/bar?baz=quz | /foo/bar?baz=quz      | /foo/bar?baz=quz      |
   +------------------+-----------------------+-----------------------+
   | /foo/bar?baz=    | /foo/bar?baz=         | /foo/bar?baz=         |
   | https://foo.bar  | https%3A%2F%2Ffoo.bar | https%3A%2F%2Ffoo.bar |
   +------------------+-----------------------+-----------------------+
   | /foo/bar/        | /foo/bar/%E3%83%84    | /foo/bar/%E3%83%84    |
   | U+E38384         |                       |                       |
   +------------------+-----------------------+-----------------------+
   | /foo/            | /foo/bar/%E3%83%84    | /foo/bar/%E3%83%84    |
   | bar/%E3%83%84    |                       |                       |
   +------------------+-----------------------+-----------------------+
   | /foo/            | /foo/bar/%62%61%7A    | /foo/bar/baz          |
   | bar/%62%61%7A    |                       |                       |
   +------------------+-----------------------+-----------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-7">
Figure 4: Examples of matching percent-encoded URI components
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-7">
図4：マッチングパーセントエンコードURIコンポーネントの例
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The crawler SHOULD ignore &#34;disallow&#34; and &#34;allow&#34; rules that are not in any group (for example, any rule that precedes the first user-agent line).
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは、どのグループにもない「禁止」および「許可」ルールを無視する必要があります（たとえば、最初のユーザーエージェント行の前にあるルールなど）。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Implementors MAY bridge encoding mismatches if they detect that the robots.txt file is not UTF-8 encoded.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
実装者は、robots.txtファイルがUTF-8エンコードされていないことを検出した場合、エンコードの不一致を橋渡しすることができます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-2-3--Special-Characters">
2.2.3. Special Characters
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.2.3. 特殊文字
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers MUST support the following special characters:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは次の特殊文字をサポートする必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
     +===========+===================+==============================+
     | Character | Description       | Example                      |
     +===========+===================+==============================+
     | #         | Designates a line | allow: / # comment in line   |
     |           | comment.          |                              |
     |           |                   | # comment on its own line    |
     +-----------+-------------------+------------------------------+
     | $         | Designates the    | allow: /this/path/exactly$   |
     |           | end of the match  |                              |
     |           | pattern.          |                              |
     +-----------+-------------------+------------------------------+
     | *         | Designates 0 or   | allow: /this/*/exactly       |
     |           | more instances of |                              |
     |           | any character.    |                              |
     +-----------+-------------------+------------------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-10">
Figure 5: List of special characters in robots.txt files
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-10">
図5：robots.txtファイルの特殊文字のリスト
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If crawlers match special characters verbatim in the URI, crawlers SHOULD use &#34;%&#34; encoding. For example:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーがURIの特殊文字と逐語的に一致する場合、クローラーは「％」エンコードを使用する必要があります。例えば：
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
    +============================+====================================+
    | Percent-encoded Pattern    | URI                                |
    +============================+====================================+
    | /path/file-with-a-%2A.html | https://www.example.com/path/      |
    |                            | file-with-a-*.html                 |
    +----------------------------+------------------------------------+
    | /path/foo-%24              | https://www.example.com/path/foo-$ |
    +----------------------------+------------------------------------+
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-19">
Figure 6: Example of percent-encoding
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-19">
図6：パーセントエンコードの例
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-2-4--Other-Records">
2.2.4. Other Records
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.2.4. その他のレコード
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers MAY interpret other records that are not part of the robots.txt protocol -- for example, &#34;Sitemaps&#34; [SITEMAPS]. Crawlers MAY be lenient when interpreting other records. For example, crawlers may accept common misspellings of the record.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは、robots.txtプロトコルの一部ではない他のレコードを解釈する場合があります。たとえば、「sitemaps」[sitemaps]。クローラーは、他のレコードを解釈するときに寛大になる場合があります。たとえば、クローラーはレコードの一般的なスペルミスを受け入れる場合があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Parsing of other records MUST NOT interfere with the parsing of explicitly defined records in Section 2. For example, a &#34;Sitemaps&#34; record MUST NOT terminate a group.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
他のレコードの解析は、セクション2の明示的に定義されたレコードの解析を妨害してはなりません。たとえば、「サイトマップ」レコードはグループを終了してはなりません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3--Access-Method">
2.3. Access Method
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3. アクセス方法
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The rules MUST be accessible in a file named &#34;/robots.txt&#34; (all lowercase) in the top-level path of the service. The file MUST be UTF-8 encoded (as defined in [RFC3629]) and Internet Media Type &#34;text/plain&#34; (as defined in [RFC2046]).
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
ルールは、サービスのトップレベルパスにある「/robots.txt」（すべて小文字）という名前のファイルでアクセスできる必要があります。ファイルは、UTF-8エンコード（[RFC3629]で定義されている）およびインターネットメディアタイプ「テキスト/プレーン」（[RFC2046]で定義されている）である必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
As per [RFC3986], the URI of the robots.txt file is:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC3986]によると、robots.txtファイルのURIは次のとおりです。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
   &#34;scheme:[//authority]/robots.txt&#34;
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
For example, in the context of HTTP or FTP, the URI is:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
たとえば、HTTPまたはFTPのコンテキストでは、URIは次のとおりです。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
             https://www.example.com/robots.txt
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
             ftp://ftp.example.com/robots.txt
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1--Access-Results">
2.3.1. Access Results
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1. アクセス結果
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1-1--Successful-Access">
2.3.1.1. Successful Access
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1.1. アクセスが成功しました
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If the crawler successfully downloads the robots.txt file, the crawler MUST follow the parseable rules.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
CrawlerがRobots.txtファイルを正常にダウンロードした場合、Crawlerは断続的なルールに従う必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1-2--Redirects">
2.3.1.2. Redirects
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1.2. リダイレクト
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
It&#39;s possible that a server responds to a robots.txt fetch request with a redirect, such as HTTP 301 or HTTP 302 in the case of HTTP. The crawlers SHOULD follow at least five consecutive redirects, even across authorities (for example, hosts in the case of HTTP).
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
サーバーは、HTTPの場合、HTTP 301やHTTP 302などのリダイレクトを使用してRobots.txt Fetchリクエストに応答する可能性があります。クローラーは、当局全体でさえ、少なくとも5つの連続したリダイレクトを追跡する必要があります（たとえば、HTTPの場合はホスト）。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If a robots.txt file is reached within five consecutive redirects, the robots.txt file MUST be fetched, parsed, and its rules followed in the context of the initial authority.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
5つの連続したリダイレクト内でrobots.txtファイルに到達した場合、robots.txtファイルをフェッチ、解析し、そのルールは初期の権限のコンテキストで行われなければなりません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If there are more than five consecutive redirects, crawlers MAY assume that the robots.txt file is unavailable.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
5つ以上の連続したリダイレクトがある場合、クローラーはrobots.txtファイルが利用できないと想定する場合があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1-3--Unavailable-Status">
2.3.1.3. &#34;Unavailable&#34; Status
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1.3. 「利用できない」ステータス
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
&#34;Unavailable&#34; means the crawler tries to fetch the robots.txt file and the server responds with status codes indicating that the resource in question is unavailable. For example, in the context of HTTP, such status codes are in the 400-499 range.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
「利用できない」とは、クローラーがrobots.txtファイルを取得しようとすることを意味し、サーバーは問題のリソースが利用できないことを示すステータスコードで応答します。たとえば、HTTPのコンテキストでは、このようなステータスコードは400〜499の範囲にあります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If a server status code indicates that the robots.txt file is unavailable to the crawler, then the crawler MAY access any resources on the server.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
サーバーステータスコードがrobots.txtファイルがクローラーに利用できないことを示している場合、クローラーはサーバー上の任意のリソースにアクセスできます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1-4--Unreachable-Status">
2.3.1.4. &#34;Unreachable&#34; Status
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1.4. 「到達不可能な」ステータス
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If the robots.txt file is unreachable due to server or network errors, this means the robots.txt file is undefined and the crawler MUST assume complete disallow. For example, in the context of HTTP, server errors are identified by status codes in the 500-599 range.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
サーバーまたはネットワークエラーのためにrobots.txtファイルが到達できない場合、これはrobots.txtファイルが未定義であり、クローラーが完全に禁止することを想定する必要があります。たとえば、HTTPのコンテキストでは、500〜599の範囲のステータスコードによってサーバーエラーが識別されます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
If the robots.txt file is undefined for a reasonably long period of time (for example, 30 days), crawlers MAY assume that the robots.txt file is unavailable as defined in Section 2.3.1.3 or continue to use a cached copy.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
robots.txtファイルが適度に長期間（たとえば30日間）未定義の場合、クローラーはrobots.txtファイルがセクション2.3.1.3で定義されているように利用できないと仮定するか、キャッシュされたコピーの使用を続けます。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-3-1-5--Parsing-Errors">
2.3.1.5. Parsing Errors
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.3.1.5. 解析エラー
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers MUST try to parse each line of the robots.txt file. Crawlers MUST use the parseable rules.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは、robots.txtファイルの各行を解析しようとする必要があります。クローラーは、断面可能なルールを使用する必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-4--Caching">
2.4. Caching
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.4. キャッシング
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers MAY cache the fetched robots.txt file&#39;s contents. Crawlers MAY use standard cache control as defined in [RFC9111]. Crawlers SHOULD NOT use the cached version for more than 24 hours, unless the robots.txt file is unreachable.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは、Fetched Robots.txtファイルのコンテンツをキャッシュする場合があります。クローラーは、[RFC9111]で定義されているように標準のキャッシュ制御を使用できます。robots.txtファイルが到達不可能でない限り、クローラーは24時間以上キャッシュバージョンを使用しないでください。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="2-5--Limits">
2.5. Limits
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
2.5. 制限
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Crawlers SHOULD impose a parsing limit to protect their systems; see Section 3. The parsing limit MUST be at least 500 kibibytes [KiB].
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
クローラーは、システムを保護するために解析制限を課す必要があります。セクション3を参照してください。解析制限は、少なくとも500キビバイト[KIB]でなければなりません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="3--Security-Considerations">
3. Security Considerations
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
3. セキュリティに関する考慮事項
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The Robots Exclusion Protocol is not a substitute for valid content security measures. Listing paths in the robots.txt file exposes them publicly and thus makes the paths discoverable. To control access to the URI paths in a robots.txt file, users of the protocol should employ a valid security measure relevant to the application layer on which the robots.txt file is served -- for example, in the case of HTTP, HTTP Authentication as defined in [RFC9110].
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
ロボット除外プロトコルは、有効なコンテンツセキュリティ対策に代わるものではありません。robots.txtファイルのリストパスは公開され、パスを発見できるようにします。robots.txtファイル内のURIパスへのアクセスを制御するには、プロトコルのユーザーは、robots.txtファイルが提供されるアプリケーションレイヤーに関連する有効なセキュリティ測定を使用する必要があります。たとえば、httpの場合、httpの場合、[RFC9110]で定義されている認証。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
To protect against attacks against their system, implementors of robots.txt parsing and matching logic should take the following considerations into account:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
システムに対する攻撃から保護するために、robots.txtの解析と一致するロジックの実装者は、次の考慮事項を考慮に入れる必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Memory management: Section 2.5 defines the lower limit of bytes that must be processed, which inherently also protects the parser from out-of-memory scenarios.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
メモリ管理：セクション2.5は、処理する必要があるバイトの下限を定義します。これは、本質的にメモリのシナリオからパーサーを保護します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Invalid characters: Section 2.2 defines a set of characters that parsers and matchers can expect in robots.txt files. Out-of-bound characters should be rejected as invalid, which limits the available attack vectors that attempt to compromise the system.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
無効な文字：セクション2.2では、パーサーとマッチャーがrobots.txtファイルで期待できる文字のセットを定義しています。バインドされていない文字は無効として拒否されるべきであり、システムを妥協しようとする利用可能な攻撃ベクトルを制限します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Untrusted content: Implementors should treat the content of a robots.txt file as untrusted content, as defined by the specification of the application layer used. For example, in the context of HTTP, implementors should follow the Security Considerations section of [RFC9110].
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
信頼されていないコンテンツ：実装者は、使用されるアプリケーションレイヤーの仕様で定義されているように、Robots.txtファイルのコンテンツを信頼されていないコンテンツとして扱う必要があります。たとえば、HTTPのコンテキストでは、実装者は[RFC9110]のセキュリティに関する考慮事項セクションに従う必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="4--IANA-Considerations">
4. IANA Considerations
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
4. IANAの考慮事項
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
This document has no IANA actions.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
このドキュメントにはIANAアクションがありません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="5--Examples">
5. Examples
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
5. 例
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="5-1--Simple-Example">
5.1. Simple Example
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
5.1. 簡単な例
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The following example shows:
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
次の例を示します。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
*: A group that&#39;s relevant to all user agents that don&#39;t have an explicitly defined matching group. It allows access to the URLs with the /publications/ path prefix, and it restricts access to the URLs with the /example/ path prefix and to all URLs with a .gif suffix. The &#34;*&#34; character designates any character, including the otherwise-required forward slash; see Section 2.2.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
*：明示的に定義されたマッチンググループを持たないすべてのユーザーエージェントに関連するグループ。/ Publications / Pathプレフィックスを備えたURLへのアクセスを可能にし、 /例 /パスプレフィックスを使用してURLへのアクセスを制限します。「*」キャラクターは、それ以外の要請されたフォワードスラッシュを含む、あらゆるキャラクターを指定します。セクション2.2を参照してください。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
foobot: A regular case. A single user agent followed by rules. The crawler only has access to two URL path prefixes on the site -- /example/page.html and /example/allowed.gif. The rules of the group are missing the optional space character, which is acceptable as defined in Section 2.2.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Foobot：通常のケース。単一のユーザーエージェントに続いてルールが続きます。クローラーは、サイト上の2つのURLパスプレフィックス（ /example/page.htmlおよび /example/allowed.gifにのみアクセスできます。グループのルールには、セクション2.2で定義されているように許容されるオプションのスペース文字がありません。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
barbot and bazbot: A group that&#39;s relevant for more than one user agent. The crawlers are not allowed to access the URLs with the /example/page.html path prefix but otherwise have unrestricted access to the rest of the URLs on the site.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Barbot and Bazbot：複数のユーザーエージェントに関連するグループ。クローラーは、 /example/page.htmlパスプレフィックスでURLにアクセスすることは許可されていませんが、サイト上の残りのURLへの無制限のアクセスがあります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
quxbot: An empty group at the end of the file. The crawler has unrestricted access to the URLs on the site.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
quxbot：ファイルの最後にある空のグループ。クローラーは、サイト上のURLへの無制限のアクセスを持っています。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
               User-Agent: *
               Disallow: *.gif$
               Disallow: /example/
               Allow: /publications/
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
               User-Agent: foobot
               Disallow:/
               Allow:/example/page.html
               Allow:/example/allowed.gif
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
               User-Agent: barbot
               User-Agent: bazbot
               Disallow: /example/page.html
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-15">
User-Agent: quxbot
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-15">
ユーザーエージェント：quxbot
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-15">
EOF
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-15">
EOF
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="5-2--Longest-Match">
5.2. Longest Match
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
5.2. 最長の試合
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
The following example shows that in the case of two rules, the longest one is used for matching. In the following case, /example/page/disallowed.gif MUST be used for the URI example.com/example/page/disallow.gif.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
次の例は、2つのルールの場合、一致に最も長いルールが使用されることを示しています。次の場合、/example/page/disallowed.gifは、uri example.com/example/page/disallow.gifに使用する必要があります。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12">
        <pre class="text text-monospace">
               User-Agent: foobot
               Allow: /example/page/
               Disallow: /example/page/disallowed.gif
        </pre>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="6--References">
6. References
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
6. 参考文献
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="6-1--Normative-References">
6.1. Normative References
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
6.1. 引用文献
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC2046] Freed, N. and N. Borenstein, &#34;Multipurpose Internet Mail Extensions (MIME) Part Two: Media Types&#34;, RFC 2046, DOI 10.17487/RFC2046, November 1996, &lt;https://www.rfc-editor.org/info/rfc2046&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC2046] Freed、N。およびN. Borenstein、「多目的インターネットメール拡張機能（MIME）パート2：メディアタイプ」、RFC 2046、DOI 10.17487/RFC2046、1996年11月、&lt;https://www.rfc-editor.orgg/info/rfc2046&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC2119] Bradner, S., &#34;Key words for use in RFCs to Indicate Requirement Levels&#34;, BCP 14, RFC 2119, DOI 10.17487/RFC2119, March 1997, &lt;https://www.rfc-editor.org/info/rfc2119&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC2119] Bradner、S。、「要件レベルを示すためにRFCで使用するためのキーワード」、BCP 14、RFC 2119、DOI 10.17487/RFC2119、1997年3月、&lt;https://www.rfc-editor.org/info/RFC2119&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC3629] Yergeau, F., &#34;UTF-8, a transformation format of ISO 10646&#34;, STD 63, RFC 3629, DOI 10.17487/RFC3629, November 2003, &lt;https://www.rfc-editor.org/info/rfc3629&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC3629] Yergeau、F。、「UTF-8、ISO 10646の変換形式」、STD 63、RFC 3629、DOI 10.17487/RFC3629、2003年11月、&lt;https://www.rfc-editor.org/info/RFC3629&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC3986] Berners-Lee, T., Fielding, R., and L. Masinter, &#34;Uniform Resource Identifier (URI): Generic Syntax&#34;, STD 66, RFC 3986, DOI 10.17487/RFC3986, January 2005, &lt;https://www.rfc-editor.org/info/rfc3986&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC3986] Berners-Lee、T.、Fielding、R。、およびL. Masinter、「Uniform Resource Identifier（URI）：Generic Syntax」、Std 66、RFC 3986、DOI 10.17487/RFC3986、2005年1月、&lt;https：//www.rfc-editor.org/info/rfc3986&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC5234] Crocker, D., Ed. and P. Overell, &#34;Augmented BNF for Syntax Specifications: ABNF&#34;, STD 68, RFC 5234, DOI 10.17487/RFC5234, January 2008, &lt;https://www.rfc-editor.org/info/rfc5234&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC5234] Crocker、D.、ed。P. Overell、「構文仕様のためのBNFの増強：ABNF：STD 68、RFC 5234、DOI 10.17487/RFC5234、2008年1月、&lt;https://www.rfc-editor.org/info/rfc5234&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC8174] Leiba, B., &#34;Ambiguity of Uppercase vs Lowercase in RFC 2119 Key Words&#34;, BCP 14, RFC 8174, DOI 10.17487/RFC8174, May 2017, &lt;https://www.rfc-editor.org/info/rfc8174&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC8174] Leiba、B。、「RFC 2119キーワードの大文字と小文字のあいまいさ」、BCP 14、RFC 8174、DOI 10.17487/RFC8174、2017年5月、&lt;https：//www.rfc-editor.org/info/RFC8174&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC8288] Nottingham, M., &#34;Web Linking&#34;, RFC 8288, DOI 10.17487/RFC8288, October 2017, &lt;https://www.rfc-editor.org/info/rfc8288&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC8288]ノッティンガム、M。、「Webリンク」、RFC 8288、DOI 10.17487/RFC8288、2017年10月、&lt;https://www.rfc-editor.org/info/rfc8288&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC9110] Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke, Ed., &#34;HTTP Semantics&#34;, STD 97, RFC 9110, DOI 10.17487/RFC9110, June 2022, &lt;https://www.rfc-editor.org/info/rfc9110&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC9110] Fielding、R.、Ed。、Ed。、Nottingham、M.、Ed。、およびJ. Reschke、ed。、 &#34;HTTP Semantics&#34;、Std 97、RFC 9110、DOI 10.17487/RFC9110、2022年6月、&lt;https：//www.rfc-editor.org/info/rfc9110&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC9111] Fielding, R., Ed., Nottingham, M., Ed., and J. Reschke, Ed., &#34;HTTP Caching&#34;, STD 98, RFC 9111, DOI 10.17487/RFC9111, June 2022, &lt;https://www.rfc-editor.org/info/rfc9111&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RFC9111] Fielding、R.、Ed。、Ed。、Nottingham、M.、Ed。、およびJ. Reschke、ed。、 &#34;Http Caching&#34;、Std 98、RFC 9111、DOI 10.17487/RFC9111、2022年6月、&lt;https：//www.rfc-editor.org/info/rfc9111&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2" id="6-2--Informative-References">
6.2. Informative References
        </h5>
      </div>
      <div class="col-sm-12 col-md-6">
        <h5 class="text mt-2">
6.2. 参考引用
        </h5>
      </div>

    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[KiB] &#34;Kibibyte&#34;, Simple English Wikipedia, the free encyclopedia, 17 September 2020, &lt;https://simple.wikipedia.org/wiki/Kibibyte&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[kib] &#34;kibibyte&#34;、シンプルな英語ウィキペディア、無料百科事典、2020年9月17日、&lt;https://simple.wikipedia.org/wiki/kibyte&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[ROBOTSTXT] &#34;The Web Robots Pages (including /robots.txt)&#34;, 2007, &lt;https://www.robotstxt.org/&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[RobotStxt]「Web Robots Pages（/robots.txtを含む）」、2007、&lt;https://www.robotstxt.org/&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[SITEMAPS] &#34;What are Sitemaps? (Sitemap protocol)&#34;, April 2020, &lt;https://www.sitemaps.org/index.html&gt;.
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
[SiteMaps]「SiteMapsとは？（SiteMap Protocol）」、2020年4月、&lt;https://www.sitemaps.org/index.html&gt;。
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
Authors&#39; Addresses
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-0">
著者のアドレス
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Martijn Koster Stalworthy Manor Farm Suton Lane Wymondham, Norfolk NR18 9JG United Kingdom Email: m.koster@greenhills.co.uk
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Martijn Koster Stalworthy Manor Farm Suton Lane Wymondham、Norfolk NR18 9JG United Kingdom Email：m.koster@greenhills.co.uk
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Gary Illyes Google LLC Brandschenkestrasse 110 CH-8002 Zürich Switzerland Email: garyillyes@google.com
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Gary Illyes Google LLC Brandschenkestrasse 110 CH-8002ZürichSwitzerlandメール：garyillyes@google.com
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Henner Zeller Google LLC 1600 Amphitheatre Pkwy Mountain View, CA 94043 United States of America Email: henner@google.com
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Henner Zeller Google LLC 1600 Amphitheater Pkwy Mountain View、CA 94043アメリカ合衆国電子メール：henner@google.com
        </p>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Lizzi Sassman Google LLC Brandschenkestrasse 110 CH-8002 Zürich Switzerland Email: lizzi@google.com
        </p>
      </div>
      <div class="col-sm-12 col-md-6">
        <p class="text indent-3">
Lizzi Sassman Google LLC Brandschenkestrasse 110 CH-8002ZürichSwitzerlandメール：lizzi@google.com
        </p>
      </div>
    </div>
  </div>
  <div id="rfc_footer"></div>
</body>
</html>
